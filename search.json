[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Health metrics and the spread of infectious diseases",
    "section": "",
    "text": "Preface\nHealth metrics and the spread of infectious diseases, with machine learning applications and spatial model analysis are the topics of this book.\nHere you will find everything you need to analyze the state of health of a country and compare it with that of other countries. You will also be able to evaluate the best model for predicting future trends.\nThe author of this book is Federica Gazzelloni actuary and a statistician by education and by training. She is also a collaborator of the Institute for Health Metrics and Evaluation (IHME) , which inspired this work to serve as a guideline for making health metrics and spatial model analysis for evaluating the state of health of a population and spread of infectious diseases.\nAll data used in this book are from the Institute for Health Metrics and Evaluation (IHME). GBD Results. Seattle, WA: IHME, University of Washington, 2020. Available from https://vizhub.healthdata.org/gbd-results/. (Accessed January 2023) and the World Health Organization (WHO). Global Health Observatory data repository. Available from https://apps.who.int/gho/data/."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "What this book is all about\nHow it can be used\nWhat is the main take away\n\nHealth metrics and the spread of infectious diseases, with machine learning applications and spatial model analysis, is a manual and a textbook for an introductory health data analysis course. It can also turn out to be a useful source code for both practitioners and data scientists.\nThis book can be used as source of set of tools for analysing data of various type but it’s born to be used for health data, such as number of infections in a population, or to identify the health status of a country.\nThere are techniques that will be evaluated as the most appropriate for certain type of analysis and other that on the contrary will be deprecated. It will be interesting to see which one is the most valuable for making predictions while another should just to be used for evaluing data consistency.\nPublic health metrics such as Years of Life Lost (YLL), and Years lived with Disability (YLD) are an example of the key metrics that will be discussed and used throughout this book. They are expressed in numbers of years of life lost or years lived with disabilities whose sum expresses a crucial value named DALYs generally used for ranking the health status of a population. The history of the development of the health metrics and a suggestion for the development of alternative ones will be proposed as a way to help providing suggestions for health policy makers.\nTo be more specific, the metrics used to summarize the state of health of a population will be then compared across other locations and a prediction level tested on a few key models will be provided. The starting point is to use {tidymodels}, and {INLA} as modeling tools, but other machine learning packages are tested, such as {mlr3} and {caret}.\nIn practice, the type of data containing information related to human kind, age, sex, life expectancy, mortality and risk levels will be evidenced.\nThe interesting part is related to the identification of the influence of some of the most dangerous infectious disease on the health metrics of a population, and this is done to practice the variation to eventually predict through model transfer techniques same pattern procedure on other countries.\nObviously, it is not the only way of application, the research needs more examples of the application of models transfers. (cit)\nA focus on the impact of recent infectious disease outbreaks, such as SARS-Covid19, on the state of health of the population, will be provided along with the most affected locations to compare results of both deterministic and Bayesian models.\nThe book is structured with an alternation of text and chunks of code, primarily in the R programming language, but hints for translations in python will be provided in appendix C, this is done to let the reader be a practitioner of real-world case studies on the topic.\nFinally, the material will allow for a full exploratory data analysis and model data visualization. It contains the code for making some interesting spatial visualization, made using {ggplot2}, {leaflet}, {sf}, {rgdal} R packages, plus other main packages for theme user customization. The main reason is to unlock the potentiality of the R language for a wider understanding of both spatial and health metrics.\nThe book is foreseen for practitioners at early stages and graduated students in STEM, but it will be useful for experts in the field who would love to have all the tools in one place to scan through as needed.\nThe book is divided into four main sections, each containing three to four subsections."
  },
  {
    "objectID": "01-HealthMetrics.html",
    "href": "01-HealthMetrics.html",
    "title": "Health metrics",
    "section": "",
    "text": "Health metrics are key variables to understand more about the state of health of a population. In this book we’ll talk about how to calculate the numbers of years of life lost (YLLs) and the numbers of years lived with disabilities (YLDs), to finally obtain the key metric of the DALYs which identify the numbers of years of life lost due to death or a disability status, namely disability adjusted life years.\n\nThe numbers of years of life lost by a population in comparison to other countries or to the Global mean trend, is based on the latest study results relative to how the well being of a country is in terms of the definition of a healthy life. To give an example, let’s think about a population whose individuals are living a good life, so defined healthy life measured on life expectancy established to be 80 years on average, as most of the World population meets this as a deadline.\nThe part of the population who do not meet this age, but dies earlier, contributes as a building block of the numbers of years of life lost (YLLs), as well as for all that is related with a healthy living, the numbers of years spent dealing with a disability contribute to increasing the numbers of years lived with disabilities for a country’s population.\nTo establish a healthy life status for a country, meaning the state of health of a population, the sum of the two values YLLs and YLDs is used to obtain the key metric of DALYs. This metric value is used to quickly identify the level of health of a population compared to a Global review based on the latest findings of the most updated studies.\nIn addition, this level is used to improve the proportion of countries who are in need of a better health status recognition. To be more specific, the focus on the numbers of years can help identify the areas where most of the years are lost and need for improvement, whether in facilities, research or investments.\nAn improvement of health at a Global level is reached when the definition of a healthy file is met in most of the countries where it wasn’t before.\nFurthermore, what we want to analyze are a series of data that are produced taking into account the tables of mortality and future life expectancy these are defined as means that these metrics have been considered important for assessing the state of health of one point population\nWhat we refer to are the health metrics and which refer to the number of years lost due to an increase in mortality or in any case to a mortality trend that is above a certain general level which we can consider as the level optimal health globally."
  },
  {
    "objectID": "01.1-Metrics.html#yll-years-of-life-lost",
    "href": "01.1-Metrics.html#yll-years-of-life-lost",
    "title": "1  YLLs, YLDs and DALYs",
    "section": "1.1 YLL (Years of Life Lost)",
    "text": "1.1 YLL (Years of Life Lost)\nYLL (Years of Life Lost) measures the number of years a person would have lived if they had not died prematurely due to a disease or injury. YLL is calculated by subtracting the age at death from the expected age at death in a population without the disease or injury."
  },
  {
    "objectID": "01.1-Metrics.html#yld-years-lived-with-disability",
    "href": "01.1-Metrics.html#yld-years-lived-with-disability",
    "title": "1  YLLs, YLDs and DALYs",
    "section": "1.2 YLD (Years Lived with Disability)",
    "text": "1.2 YLD (Years Lived with Disability)\nYLD (Years Lived with Disability) measures the number of years a person lives with a disability due to a disease or injury. It is calculated by multiplying the prevalence of a condition by the disability weight, which reflects the severity of the disability."
  },
  {
    "objectID": "01.1-Metrics.html#daly-disability-adjusted-life-year",
    "href": "01.1-Metrics.html#daly-disability-adjusted-life-year",
    "title": "1  YLLs, YLDs and DALYs",
    "section": "1.3 DALY (Disability-Adjusted Life Year)",
    "text": "1.3 DALY (Disability-Adjusted Life Year)\nDALY (Disability-Adjusted Life Year) is a measure of overall disease burden and is calculated as the sum of years of potential life lost due to premature death (YLL) and years lived with disability (YLD). The DALY takes into account both the quantity and quality of life lost due to disease or injury.\nThe YLL and YLD are components of the DALY, which are used to assess how diseases and injuries impact populations. As a result, @sec-ch12Components section provides a more comprehensive picture of the overall burden of disease by combining YLLs and YLDs in different life expectancy groups."
  },
  {
    "objectID": "01.1-Metrics.html#how-the-metrics-are-used",
    "href": "01.1-Metrics.html#how-the-metrics-are-used",
    "title": "1  YLLs, YLDs and DALYs",
    "section": "1.4 How the metrics are used",
    "text": "1.4 How the metrics are used\nThe health metrics of DALY, YLL, and YLD can be used in several ways to help prioritize public health interventions, evaluate the impact of diseases and injuries, and inform public health decision-making. Some common uses of these metrics include:\nPrioritizing public health interventions: By calculating the overall burden of disease in a population, public health practitioners can prioritize which diseases and injuries to address first. This helps allocate resources and target interventions to the areas of greatest need.\nEvaluating the impact of diseases and injuries: These metrics can be used to measure the impact of diseases and injuries on individuals and populations and to track changes over time. This information can help inform public health decision-making and allocate resources more effectively.\nComparing the burden of disease across populations: DALY, YLL, and YLD can be used to compare the burden of disease across populations and between different regions. This information can help identify disparities in health outcomes and inform targeted public health interventions.\nEvaluating the effectiveness of public health programs: These metrics can be used to evaluate the impact of public health programs and to assess the effectiveness of public health interventions. This information can help public health practitioners identify areas for improvement and make necessary changes to ensure that programs are achieving their goals.\nMonitoring global health trends: DALY, YLL, and YLD can also be used to monitor global health trends and track changes in the burden of disease over time. This information can be used to inform global health policies and allocate resources to address emerging health threats.\nOverall, the health metrics of DALY, YLL, and YLD provide valuable information for public health practitioners, researchers, and policy makers to help prioritize and allocate resources, evaluate the impact of diseases and injuries, and inform public health decision-making."
  },
  {
    "objectID": "01.2-Components.html#build-the-metrics",
    "href": "01.2-Components.html#build-the-metrics",
    "title": "2  Metrics components",
    "section": "\n2.1 Build the metrics",
    "text": "2.1 Build the metrics\n\n2.1.1 Life tables and Life expectancy\nTwo fundamental components are used for calculating the YLL are:\n\nlife tables\nlife expectancy\n\nBoth of these elements are key for achieving the highest value of prediction of the state of health of a population.\n\n2.1.1.1 Life tables\nThe life tables are selected among the most frequently used, more information about how to build a like table can be found in the Appendix A of this book.\n\nHide codelibrary(tidyverse)\nlibrary(infectious)\n\n\nGlifetables contains five variables:\n\n\nindicator:\n\n\n\n\n\nindicator\n\n\n\nTx - person-years lived above age x\n\n\nex - expectation of life at age x\n\n\nlx - number of people left alive at age x\n\n\nnLx - person-years lived between ages x and x+n\n\n\nnMx - age-specific death rate between ages x and x+n\n\n\nndx - number of people dying between ages x and x+n\n\n\nnqx - probability of dying between ages x and x+n\n\n\n\n\n\n\nage group: from 1 to 85+ in 5-year classes\nsex: female, male, and both\nvalue\n\n\nHide code #| echo: false\nGlifetables %>%\n  mutate(indicator = sub(\" -.*$\", \"\", indicator)) %>%\n  group_by(indicator) %>%\n  summarize(value = round(mean(value), 3))\n\n#> # A tibble: 7 × 2\n#>   indicator       value\n#>   <chr>           <dbl>\n#> 1 Tx        2652370.   \n#> 2 ex             31.3  \n#> 3 lx          70145.   \n#> 4 nLx        313032.   \n#> 5 nMx             0.041\n#> 6 ndx          5263.   \n#> 7 nqx             0.16\n\n\n\n\nyear: from 2000 to 2019\n\n2.1.1.2 Life expectancy\nThe life expectancy rates are calculated with consideration of the probability of survival based on key parameter such as age, and deaths probabilities for that age. More info about how to calculate the life expectancy can be found in the Appendix A section of this book.\nThis visualization of the ex - expectation of life at age x shows for each age group its changing level across the years.\n\nHide codeGlifetables %>%\n  filter(indicator == \"ex - expectation of life at age x\") %>%\n  ggplot(aes(year, value, group = age_group, color = age_group)) +\n  geom_line() +\n  facet_wrap(vars(sex)) +\n  labs(title = \"ex - expectation of life at age x\") +\n  theme_bw()"
  },
  {
    "objectID": "01.2-Components.html#how-to-build-the-ylls-a-practical-example",
    "href": "01.2-Components.html#how-to-build-the-ylls-a-practical-example",
    "title": "2  Metrics components",
    "section": "\n2.2 How to build the YLLs: a practical example",
    "text": "2.2 How to build the YLLs: a practical example\nIn this section a practical calculation of the health metrics is done for the practitioner to be able to replicate this calculation for further analysis based on these key elements.\n\nHide codeGermany_lungc %>%\n  full_join(\n    Glifetables %>%\n      filter(year == 2019,\n             indicator == \"ex - expectation of life at age x\") %>%\n      rename(life_expectancy = value),\n    by = c(\"age_group\", \"sex\")\n  ) %>%\n  select(-upper, -lower, -year, -indicator) %>%\n  group_by(age_group) %>%\n  mutate(YLL = val * life_expectancy) %>%\n  filter(!is.na(YLL)) %>%\n  head()\n\n#> # A tibble: 6 × 5\n#> # Groups:   age_group [2]\n#>   sex    age_group   val life_expectancy   YLL\n#>   <chr>  <chr>     <dbl>           <dbl> <dbl>\n#> 1 male   10-14     0.322            57.7  18.5\n#> 2 female 10-14     0.457            57.0  26.1\n#> 3 both   10-14     0.779            57.3  44.6\n#> 4 male   15-19     1.27             52.8  67.2\n#> 5 female 15-19     1.56             52.1  81.1\n#> 6 both   15-19     2.83             52.4 148.\n\n\n\n\n\n\nReiner, Robert C., and Simon I. Hay. 2022. “The Overlapping Burden of the Three Leading Causes of Disability and Death in Sub-Saharan African Children.” Nature Communications 13 (1): 7457. https://doi.org/10.1038/s41467-022-34240-6."
  },
  {
    "objectID": "01.3-Causes.html",
    "href": "01.3-Causes.html",
    "title": "3  Causes and risks",
    "section": "",
    "text": "How to use the metrics\nOverview of the causes and risks\n\nConditions and injuries that are associated with the burden of disease and injury vary according to their specific causes and risks. However, some common causes and risk factors include:\n\nLifestyle choices: Poor diet, physical inactivity, tobacco use, and excessive alcohol consumption are major risk factors for many chronic diseases and injuries, including heart disease, stroke, cancer, and liver disease.\nEnvironmental factors: Exposure to pollutants, such as air pollution and toxic chemicals, can increase the risk of certain diseases and injuries.\nInfections: Many diseases, such as tuberculosis, HIV/AIDS, and malaria, are caused by infectious agents.\nPoverty: People living in poverty are often more susceptible to health problems due to limited access to healthcare, healthy food, and safe living conditions.\nAging: As people get older, they are at an increased risk of many health problems, including chronic diseases and disabilities.\nGenetics: Some diseases and injuries are caused by genetic factors, such as a genetic predisposition to certain cancers.\nInjuries: Injuries, such as falls, road traffic accidents, and violence, can also contribute to the burden of diseases and injuries.\n\n\nA particular health condition can have multiple causes and risk factors. For example, poverty and lack of access to healthcare can increase the risk of infectious diseases, while poor diet and physical inactivity can increase the risk of chronic diseases. Addressing the underlying causes and risk factors for diseases and injuries is a key component of public health interventions and can help reduce the overall burden of disease.\nAs an example here is shown how the DALY metric can be used for prevention:\nSuppose we have data on the number of cases of a particular disease, as well as the average number of years of life lost due to this disease. We can use this information to calculate the total number of DALYs lost due to this disease.\n\nHide code# Load the library 'dplyr'\nlibrary(dplyr)\n\n# Create a data frame with the number of cases and average years of life lost\ndf <- data.frame(YLL = c(5, 10, 15),\n                 YLD = c(1,3,4))\n\n# Calculate the number of DALYs lost\ndf <- df %>% mutate(DALY = YLL + YLD)\n\n# Sum the total number of DALYs lost\ntotal_dalys <- sum(df$DALY)\ntotal_dalys\n\n#> [1] 38\n\n\nIn this example, the number of cases of the disease and the average years of life lost for each case are used to calculate the number of DALYs lost for each case. Finally, the total number of DALYs lost for the entire population.\nThis information can be used to inform public health interventions to prevent the spread of this disease and reduce the number of DALYs lost. For example, the information could be used to prioritize resources for disease control and prevention activities, such as health education campaigns, vaccination programs, and screening and treatment programs."
  },
  {
    "objectID": "01.4-Metrics2.html#hale-healthy-life-expectancy",
    "href": "01.4-Metrics2.html#hale-healthy-life-expectancy",
    "title": "4  Healthy life expectancy (HALE)",
    "section": "4.1 HALE (Healthy Life Expectancy)",
    "text": "4.1 HALE (Healthy Life Expectancy)\nThe health metric of HALE (Healthy Life Expectancy) is a measure of overall health and well-being that takes into account both quantity and quality of life. It is a composite measure that combines years of life expectancy with a measure of the prevalence and severity of disability in a population. HALE provides a more comprehensive view of health outcomes than traditional measures of life expectancy, which only consider the quantity of life.\nThe calculation of HALE typically involves estimating the number of years that an individual can expect to live in good health, taking into account the impact of diseases and injuries on quality of life. This information is then used to estimate the overall health status of a population.\nHALE is a useful tool for public health practitioners and policy makers, as it provides a more nuanced view of the health outcomes of a population. This information can help inform public health interventions and prioritize resources, as well as help track changes in health outcomes over time. Additionally, HALE can be used to compare the health outcomes of different populations and identify disparities in health outcomes, which can help inform targeted public health interventions.\nOverall, the HALE metric provides a valuable perspective on the overall health and well-being of a population, combining information about both quantity and quality of life to provide a comprehensive view of health outcomes.\nIt adjusts overall life expectancy by the amount of time lived in less than perfect health. This is calculated by subtracting from the life expectancy a figure which is the number of years lived with disability multiplied by a weighting to represent the effect of the disability.1\nMore info 2"
  },
  {
    "objectID": "02-Modeling.html#model-description",
    "href": "02-Modeling.html#model-description",
    "title": "Modeling",
    "section": "Model description",
    "text": "Model description\nThis book aims at providing a simple explanation at how to model a fast growing phenomenon such as in the case of the spread of infectious diseases, or the performance of health metrics for some countries. In addition, a further look will be provided at the evolution of the infection in some specific countries, and how this influences the level of health metrics.\nA stochastic process, or random process (see Dobrow 2016) is the type of model which attempt to replicate uncertain outcomes. At opposite, in a deterministic system the outcome is obtained from a given input, and for this reason it is reproducible.\nThe spread of a virus can be seen as a random process, since the number of individuals who are infected at any given time can change randomly. The exact number of individuals who will be infected in the future cannot be determined with certainty, since it depends on various factors such as the contagiousness of the virus, the behavior of individuals, and the efficacy of mitigation measures.\nA deterministic model, on the other hand, could be used to model the spread of a virus under certain conditions, such as a fixed number of individuals, constant contagiousness, and no mitigation measures. This type of model can be used to make predictions about the spread of a virus under certain assumptions, but it will not account for the randomness and uncertainty associated with real-world scenarios.\nMost models used to study the spread of a virus are a combination of both deterministic and stochastic models. For example, the SIR (Susceptible-Infected-Recovered) model is a deterministic model that describes the dynamics of the spread of a virus, but it also includes stochastic elements such as random interactions between individuals.\nThe spread of COVID-19\nHere is a model example of the spread of COVID-19 using a stochastic process. In this example, we’ll use a simple SEIR (Susceptible-Exposed-Infected-Recovered) model to simulate the spread of the virus in a population. The SEIR model divides a population into four compartments based on their status with respect to the virus: susceptible, exposed, infected, and recovered.\nFirst, we’ll load the necessary packages and define some parameters for our model:\n\nHide codelibrary(deSolve)\n\n# Define parameters\nN <- 1e6  # Total population\nbeta <- 0.5  # Transmission rate\ngamma <- 0.1  # Recovery rate\nt_exp <- 5  # Latent period\n\n# Initial conditions\ninit <- c(S = N - 1, E = 1, I = 0, R = 0)\n\n# Define the SEIR model\nseir_model <- function(t, y, parameters) {\n  with(as.list(y), {\n    dS <- -beta * S * I / N\n    dE <- beta * S * I / N - (1 / t_exp) * E\n    dI <- (1 / t_exp) * E - gamma * I\n    dR <- gamma * I\n    return(list(c(dS, dE, dI, dR)))\n  })\n}\n\n\nNext, we’ll use the ode function from the deSolve package to solve the ODEs and simulate the spread of the virus over a period of 365 days:\n\nHide code# Solve the ODEs\ntimes <- seq(0, 365, by = 1)\nresult <- ode(y = init, times = times, func = seir_model)\n\n# Plot the results\nlibrary(ggplot2)\nggplot(as.data.frame(result), aes(time, I, color = \"Infected\")) +\n  geom_line() +\n  geom_line(aes(time, R, color = \"Recovered\")) +\n  geom_line(aes(time, S, color = \"Susceptible\")) +\n  geom_line(aes(time, E, color = \"Exposed\")) +\n  scale_color_discrete(name = \"Compartment\") +\n  labs(x = \"Time (days)\", y = \"Number of individuals\") +\n  theme_bw()\n\n\n\n\nIn this example, many factors are not taken into account. In reality, the spread of a virus is much more complex and influenced by many factors such as human behavior, government policies, and healthcare systems.\n\n\n\n\nDobrow, Robert P. 2016. Introduction to Stochastic Processes with R. John Wiley & Sons."
  },
  {
    "objectID": "02.1-Techniques.html",
    "href": "02.1-Techniques.html",
    "title": "5  Techniques",
    "section": "",
    "text": "Data collection\nFeature engineering\nModel selection\n\nCollecting data to use in a research analysis involves a selection of sources and methods to use for optimizing computational time when downloading and reading the files.\nOnce data is set and ready to use a further step is required to make the data suitable for the selected model.\nIn this chapter, an overview of different method of data loading and featuring selection is provided before to get into selecting the best model to use.\nThe source of data is an important variable. Generally, data can be downloaded by using an API (application programming interface) which allow the user to get access to data directly from source, with the use of specified back-end computations. There are alternatives at using an API; data can be obtained by downloading it directly into the computer, or loaded through library packages.\nUsually, available files are provided under various forms such as delimited type of files, .csv, .xls, .json, and other types.\nHere is an example of how to use an API for downloading a file directly onto your computer.\n\nHide codelibrary(httr)\nurl <- \"\"\nhttr::GET(url = url)\n\n\nOnce data is on your computer available and ready to use, the next step is to have a look at it and decide whether to perform some adjustment to the data to make it suitable for your model.\nThis step includes:\n\ndata manipulation/wrangling\nfeaturing engineering\nexploratory data analysis\n\nLet’s use the HistData package for an example on William Farr’s Data on Cholera in London, 1849. This set of data contains information about the number of deaths due to Cholera in specific districts, the population density, the water provider and other variables.\nThis is a type of dataset which can be considered ready to use for some type of models such as linear regression models, but it would require some adjustments if a Bayesian approach is desired.\n\nHide codelibrary(tidyverse)\nlibrary(HistData)\nCholera <- HistData::Cholera\nCholera%>%head\n\n#>              district cholera_drate cholera_deaths  popn elevation region\n#> 1           Newington           144            907 63074        -2   Kent\n#> 2         Rotherhithe           205            352 17208         0   Kent\n#> 3          Bermondsey           164            836 50900         0   Kent\n#> 4 St George Southwark           161            734 45500         0   Kent\n#> 5            St Olave           181            349 19278         2   Kent\n#> 6          St Saviour           153            539 35227         2   Kent\n#>       water annual_deaths pop_dens persons_house house_valpp poor_rate area\n#> 1 Battersea           232      101           5.8       3.788     0.075  624\n#> 2 Battersea           277       19           5.8       4.238     0.143  886\n#> 3 Battersea           267      180           7.0       3.318     0.089  282\n#> 4 Battersea           264       66           6.2       3.077     0.134  688\n#> 5 Battersea           281      114           7.9       4.559     0.079  169\n#> 6 Battersea           292      141           7.1       5.291     0.076  250\n#>   houses house_val\n#> 1   9370    207460\n#> 2   2420     59072\n#> 3   6663    155175\n#> 4   5674    107821\n#> 5   2523     90583\n#> 6   4659    174732\n\n\nIf we are interested in the evolution of mortality due to Cholera. We might want to look at the regional level, how the annual deaths - all causes (annual_deaths), the death’s rate per 10,000 inhabitants (cholera_drate), or is distributed.\n\nHide codedata <- Cholera%>%\n  select(region,cholera_drate,contains(\"death\",ignore.case=T))\n\ndata %>%\n  head\n\n#>   region cholera_drate cholera_deaths annual_deaths\n#> 1   Kent           144            907           232\n#> 2   Kent           205            352           277\n#> 3   Kent           164            836           267\n#> 4   Kent           161            734           264\n#> 5   Kent           181            349           281\n#> 6   Kent           153            539           292\n\n\n\nHide codedata %>%\n  select(-region)%>%\n  scale()%>%\n  bind_cols(region=data$region)%>%\n  pivot_longer(cols = 1:3,names_to = \"type\",values_to = \"values\")%>%\n  ggplot(aes(values))+\n  geom_density()+\n  facet_wrap(~type)"
  },
  {
    "objectID": "04-CaseStudies.html",
    "href": "04-CaseStudies.html",
    "title": "Case Studies",
    "section": "",
    "text": "In this section we will be looking at two case studies:\n\nCovid19 spread of infection as a cause for increased DALY for selected countries.\nThe state of health of selected countries.\n\nA systematic review study namely summarized the results of all studies containing DALYs, YLLs and YLDs metrics for the European countries from 2010 to 2019. The result of the review shown a steady improvement of the DALY metrics in almost all countries of Europe. Cardiovascular and neoplasms account for most of deaths and increase in numbers of years lost in EU 2019. Important improvements in some areas (e.g. transport injuries) are opposite ar the increasing level of diabetes spread in the population."
  },
  {
    "objectID": "04.1-Covid19.html#infectious-diseases-the-invisible-enemies",
    "href": "04.1-Covid19.html#infectious-diseases-the-invisible-enemies",
    "title": "11  Covid19",
    "section": "\n11.1 Infectious Diseases the invisible enemies",
    "text": "11.1 Infectious Diseases the invisible enemies\nThe infective agent begins to thrive and multiply throughout the body (see Broemeling 2021). Its prolifaration can be fast or slow depending on the type of organism. Every infectious disease has an incubation period, the length of time the pathogen is established until appearance of symptoms of the disease.\nFactors influencing infection\n\nquantity of invading germs (dose of the infection)\nthe virulence of the infection\nthe condition of the body’s immune system\ncontact with source of infection for contagious diseases\n\nMicroorganisms adapt far more rapidly than humans as the scene shifts\nA bacterial generation ranges from 20-30 minutes, for viruses it’s much smaller\n\nWho is going to adapt to whom?\n\nVirus means poisonous substance ranging from 20 to 400 nm in diameter can be observed only with a electron microscope. Outside of a living cell is a dormant particle of strange shapes. When manage to get inside the cell it starts replicating killing the cell or skewing its functions.\nThe Bayesian Analysis of Infectious Diseases: COVID-19 and Beyond book is a comprehensive resource that covers the use of Bayesian analysis in the modeling of infectious diseases, including COVID-19.\nIn the context of modeling COVID-19 in R, the following steps can be taken:\nDefine the model structure: The first step is to define the model structure, which involves specifying the underlying mechanisms of disease spread and the parameters of interest. For COVID-19, the model structure might include the number of susceptible individuals, the number of infected individuals, the number of recovered individuals, and the rate of disease transmission.\nSpecify the prior distributions: The next step is to specify the prior distributions for the parameters of interest. This involves defining the prior beliefs about the values of the parameters based on available data and expert knowledge. In the case of COVID-19, this might include prior beliefs about the rate of disease transmission, the incubation period, and the rate of recovery.\nCollect data: The next step is to collect relevant data on the spread of the disease. This might include the number of confirmed cases, the number of hospitalizations, and the number of deaths.\nImplement the model in R: Once the model structure and prior distributions have been specified, the model can be implemented in R using a variety of packages, including Stan, JAGS, or MCMCpack.\nEstimate the parameters: The next step is to use the data and the model to estimate the parameters of interest. This can be done using Bayesian Markov Chain Monte Carlo (MCMC) methods, which involve drawing a large number of samples from the posterior distributions of the parameters.\nEvaluate the model: The final step is to evaluate the performance of the model, which involves comparing the model predictions with the observed data and checking the validity of the model assumptions.\nThis is a general outline of the steps involved in modeling COVID-19 in R using Bayesian analysis. The specific details of the implementation will depend on the particular model structure and data being used.\nSuppose we have data on the number of confirmed cases of COVID-19 in a region for a period of time, and we want to model the spread of the disease.\nStep 1: Define the model structure\nWe can use the Susceptible-Infected-Recovered (SIR) model to describe the spread of the disease, where S represents the number of susceptible individuals, I represents the number of infected individuals, and R represents the number of recovered individuals. The model structure can be described as follows:\n\\[dS/dt = -beta * S * I / N\\] \\[dI/dt = beta * S * I / N - gamma * I\\] \\[dR/dt = gamma * I\\]\nwhere beta is the rate of transmission, gamma is the rate of recovery, and N is the total population.\nStep 2: Specify the prior distributions\nWe can specify the prior distributions for beta and gamma using expert knowledge and available data. For example, we might specify a gamma distribution with a mean of 0.1 and a standard deviation of 0.05 for beta, and a gamma distribution with a mean of 0.05 and a standard deviation of 0.02 for gamma.\nStep 3: Collect data\nWe can collect data on the number of confirmed cases of COVID-19 in the region for a period of time.\nStep 4: Implement the model in R\nWe can use the rstan package in R to implement the model, as follows:\n\nHide code# Load the rethinking package\nlibrary(rethinking)\nlibrary(rstan)\nlibrary(tidyverse)\n\n# Load the data\nsource(\"inst/scripts/covid19_sim_data.R\")\ndata <- out\n\n# Define the model\nSIR_model <- function(data) {\n  # Define the priors\n  beta <- dnorm(0, 0.01)\n  gamma <- dnorm(0, 0.01)\n  I0 <- dnorm(0, 0.01)\n\n  # Define the model\n  S <- numeric(length(data$Time))\n  I <- numeric(length(data$Time))\n  R <- numeric(length(data$Time))\n  S[1] <- 1 - I0\n  I[1] <- I0\n  for (t in 2:length(data$Time)) {\n    S[t] <- S[t - 1] - beta * S[t - 1] * I[t - 1]\n    I[t] <- I[t - 1] + beta * S[t - 1] * I[t - 1] - gamma * I[t - 1]\n    R[t] <- R[t - 1] + gamma * I[t - 1]\n  }\n\n  # Likelihood\n  dpois(data$y, lambda = I)\n}\n\n\nStep 5: Estimate the parameters\nWe can use the sampling function in the rstan package to estimate the parameters, as follows:\n\nHide codedata <- alist(\n  time<- data$time,\n  S<-data$S,\n  I<-data$I,\n  R<-data$R\n)\n\n\nStep 6: Evaluate the model\nWe can evaluate the performance of the model by comparing the model predictions with the observed data and checking the validity\n\nHide code# Plot the observed data and the model predictions\nlibrary(ggplot2)\n\npredictions <- extract(results)$I\n\ndata.frame(Time = data$Time, \n           Observed = data$y, \n           Predicted = predictions) %>%\n  ggplot(aes(x = Time, y = Observed)) +\n  geom_line(aes(y = Predicted, color = \"Predicted\")) +\n  geom_line(aes(y = Observed, color = \"Observed\"), \n            linetype = \"dashed\") +\n  scale_color_discrete(name = NULL, labels = c(\"Predicted\", \"Observed\")) +\n  labs(x = \"Time\", y = \"Number of Confirmed Cases\") +\n  theme_bw()\n\n# Calculate the goodness-of-fit measures\nrmse <- sqrt(mean((data$y - predictions)^2))\nmae <- mean(abs(data$y - predictions))\nr2 <- cor(data$y, predictions)^2\ncat(\"RMSE:\", rmse, \"\\n\")\ncat(\"MAE:\", mae, \"\\n\")\ncat(\"R-squared:\", r2, \"\\n\")\n\n# Plot the posterior distribution of the parameters\nlibrary(bayesplot)\nmcmc_areas(results, pars = c(\"beta\", \"gamma\", \"I0\"),\n           prob = 0.89, ROPE = c(0.05, 0.1),\n           prob_lines = TRUE, prob_args = list(col = \"red\"),\n           rope_args = list(col = \"blue\"),\n           main = \"Posterior Distribution of Parameters\")\n\n\n\n\n\n\nBroemeling, Lyle D. 2021. Bayesian Analysis of Infectious Diseases: COVID-19 and Beyond. New York: Chapman; Hall/CRC. https://doi.org/10.1201/9781003125983."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Here are a few sources that provide more information on the health metrics of DALY, YLL, YLD, and HALE:\nWorld Health Organization (WHO): The WHO provides comprehensive information on the health metrics of DALY, YLL, and YLD, including definitions, calculation methods, and applications.\nGlobal Burden of Disease (GBD) Study: The GBD study is an ongoing research effort that provides comprehensive information on the burden of diseases, injuries, and risk factors at the global, regional, and country levels. It is based on data from a wide range of sources and provides estimates of the number of DALYs, YLLs, and YLDs for hundreds of diseases and injuries.\nInstitute for Health Metrics and Evaluation (IHME): The IHME is a research institute that conducts the GBD study and provides data and tools for understanding the health of populations around the world.\nJournal of Public Health: The Journal of Public Health is a peer-reviewed publication that provides a platform for research on public health and health policy. It includes articles that provide further insights into the use and application of DALY, YLL, YLD, and HALE, as well as other health metrics.\nThese sources can provide more information on the health metrics of DALY, YLL, YLD, and HALE, as well as provide a deeper understanding of how these metrics are used in public health and health policy.\nsee Who documentation:\n\nhttps://cdn.who.int/media/docs/default-source/gho-documents/global-health-estimates/ghe2019_cod_methods.pdf\n\nlife tables:\n\nhttps://apps.who.int/gho/data/node.main.LIFECOUNTRY?lang=en\nhttps://ghdx.healthdata.org/record/ihme-data/gbd-2019-life-tables-1950-2019\nhttps://www.sciencedirect.com/topics/medicine-and-dentistry/life-table"
  },
  {
    "objectID": "appendixA.html#life-expectancy",
    "href": "appendixA.html#life-expectancy",
    "title": "Appendix A — Life tables and Life expectancy",
    "section": "\nA.1 Life expectancy",
    "text": "A.1 Life expectancy\nLife expectancy is the expected number of years a person will live, based on current age and prevailing mortality rates. There are several methods to calculate life expectancy, but one common approach is to use the actuarial life table, which is a statistical table that provides the mortality rates for a population at different ages. The following steps can be used to calculate life expectancy using a life table:\nIdentify the relevant mortality rates for the population and time period of interest. Calculate the probability of surviving to each age, given the mortality rates. Multiply the probability of surviving to each age by the remaining life expectancy at that age to obtain the expected number of years of life remaining at each age. Sum the expected number of years of life remaining at each age to obtain the total life expectancy. Note that life expectancy is a statistical estimate and can be influenced by many factors, such as lifestyle, health, and environmental factors, so actual individual life expectancies can vary widely.\nHere are some key references for calculating life expectancy:\n\nUnited Nations World Population Prospects - The UN provides detailed life tables and population data, including life expectancy, for countries and regions around the world.\nCenters for Disease Control and Prevention (CDC) - The CDC provides life tables for the United States, as well as information on how life expectancy is calculated and factors that affect it.\nWorld Health Organization (WHO) - The WHO provides information on global health and life expectancy, including data and reports on trends in life expectancy and mortality.\nActuarial Science textbooks - Books such as “Actuarial Mathematics” by Bowers, Gerber, Hickman, Jones, and Nesbitt, or “An Introduction to Actuarial Mathematics” by Michel Millar, provide comprehensive coverage of the methods and mathematics used in calculating life expectancy.\nJournal articles - Articles in actuarial and demographic journals, such as the North American Actuarial Journal or Demographic Research, often provide in-depth coverage of the latest research and methods for calculating life expectancy.\n\n\n\n\n\nKovacheva, Ts. P. 2017. “Life Tables - Key Parameters and Relationships Between Them.” International Mathematical Forum 12: 469–79. https://doi.org/10.12988/imf.2017.7225.\n\n\n“Life Table - an Overview | ScienceDirect Topics.” n.d. https://www.sciencedirect.com/topics/medicine-and-dentistry/life-table.\n\n\n“Modified Logit Life Table System: Principles, Empirical Validation, and Application: Population Studies: Vol 57, No 2.” n.d. https://www.tandfonline.com/doi/abs/10.1080/0032472032000097083."
  },
  {
    "objectID": "appendixB.html#rstudio-installation",
    "href": "appendixB.html#rstudio-installation",
    "title": "Appendix B — Tools used to make this book",
    "section": "B.1 RStudio installation",
    "text": "B.1 RStudio installation\nDownload and install R: Download and install RStudio IDE:"
  },
  {
    "objectID": "appendixB.html#info-on-how-to-setup-this-project-in-quarto",
    "href": "appendixB.html#info-on-how-to-setup-this-project-in-quarto",
    "title": "Appendix B — Tools used to make this book",
    "section": "B.2 Info on how to setup this project in quarto",
    "text": "B.2 Info on how to setup this project in quarto\nquarto is the new version of Rmarkdown, it can be used for making notes, presentations, websites, books and more.\nIn this project the book has been made in quarto and version saved on github.\nQuarto publishing\n\nB.2.1 GitHub useful commands\nYou can do the same using the command line. In RStudio create a new project on a new directory, add git, and select quarto book project\nThe automated process will create a _quarto.yml file, the top of the file will look like this one:\nproject:\n  type: book\nOn terminal type: quarto preview\nIt creates a folder _book\n\nB.2.1.1 Add Github later:\nexisting-github-last to connect with github create a github repo with the same name of your project then type\nusethis::use_git()\nIt asks you to commit all files in the RStudio project. This pushes all files in R to a remote folder designed to head to the github repo.\nIn terminal connect with the github repo:\ngit init \ngit remote add origin\nhttps://github.com/Fgazzelloni/infectious.git\ngit branch -M main \ngit push -u origin main \n\n\n\nB.2.2 Publish your book on github pages\nchange the quarto.yml file into:\nproject: \n  type: book \n  output-dir: docs \nadd a .nojekyll file, type in terminal:\ntouch .nojekyll \nthen type\nquarto render \nsome issues might arise if more than one calculation is made inside a single chunks split the chunks!\nquarto render creates a folder docs"
  },
  {
    "objectID": "appendixB.html#add-a-package",
    "href": "appendixB.html#add-a-package",
    "title": "Appendix B — Tools used to make this book",
    "section": "B.3 Add a package",
    "text": "B.3 Add a package\ndevtools::create(\"yourpkg\")\nNow that you have your book done, you might need to add some customized data to use within your analysis.\nIn order to do that, you’ll need to just add data in the way that is usually done when inside a package.\n\nB.3.1 Building blocks of the package inside the quarto book\n\nB.3.1.1 ADD DATA TO PACKAGE\nset the data from the original source and tidy appropriately\nusethis::use_data_raw()\nit creates a .R script where to put the steps for get the data ready\nonce data are ready\nusethis::use_data(yourdata)\nIt creates the R folder where the .R scripts of data documentation is located\nusethis::use_r(\"yourdataset\")\nread how to document your work\nvignette(\"rd-other\") # for datasets\nvignette(\"rd\")\n\ndevtools::document()\ndevtools::load_all(\".\")\n\n\nB.3.1.2 ADD PACKAGE INFO\nso the ? (NAMESPACE) works\nusethis::use_package_doc()\ndevtools::document()\n\n\nB.3.1.3 ADD DATA PACKAGE INFO\nusethis::use_r(\"yourdataset\")\ndevtools::document()\nwhen filling the data .R script for explaining what’s inside the dataset a specific structure needs to be used (see examples)\nwhen new data are added\nBuild tab and —> More —> clean and install (this is not there anymore whae you start with devtools::create(\"yourpkg\")) to add the new data to NAMESPACE"
  }
]